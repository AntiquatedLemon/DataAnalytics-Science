{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc15be-d374-4ef6-b6b4-5829eb003910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec7c19-da30-47ed-a3b4-57e4363de6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "import math\n",
    "\n",
    "def ensemble_error(n_classifier, error):\n",
    "    k_start = int(math.ceil(n_classifier / 2.))\n",
    "    probs = [comb(n_classifier, k) * error**k * (1-error)**(n_classifier - k)\n",
    "             for k in range(k_start, n_classifier + 1)]\n",
    "    return sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51952a-5603-41bb-af11-1350ff35cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_error(n_classifier=11, error=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2dbc4-df7c-4980-9f2f-fa5d0a97b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "error_range = np.arange(0.0, 1.01, 0.01)\n",
    "ens_errors = [ensemble_error(n_classifier=11, error=error)\n",
    "              for error in error_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf35fa-d2fc-4a7c-a9ed-05e2e7f90832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(error_range, \n",
    "         ens_errors, \n",
    "         label='Ensemble error', \n",
    "         linewidth=2)\n",
    "\n",
    "plt.plot(error_range, \n",
    "         error_range, \n",
    "         linestyle='--',\n",
    "         label='Base error',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlabel('Base error')\n",
    "plt.ylabel('Base/Ensemble error')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.5)\n",
    "#plt.savefig('images/07_03.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b8aa0-045f-408a-9584-0205fbefd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argmax(np.bincount([0, 0, 1], \n",
    "                      weights=[0.2, 0.2, 0.6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb0260-c09b-4814-9595-c8f8a1c6097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = np.array([[0.9, 0.1],\n",
    "               [0.8, 0.2],\n",
    "               [0.4, 0.6]])\n",
    "\n",
    "p = np.average(ex, \n",
    "               axis=0, \n",
    "               weights=[0.2, 0.2, 0.6])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563c898-d9ce-455c-8c0b-f69854d1f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78808896-ca69-4ccb-ac68-a5f233c9358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, \n",
    "                             ClassifierMixin):\n",
    "    \"\"\" A majority vote ensemble classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : array-like, shape = [n_classifiers]\n",
    "      Different classifiers for the ensemble\n",
    "\n",
    "    vote : str, {'classlabel', 'probability'} (default='classlabel')\n",
    "      If 'classlabel' the prediction is based on the argmax of\n",
    "        class labels. Else if 'probability', the argmax of\n",
    "        the sum of probabilities is used to predict the class label\n",
    "        (recommended for calibrated classifiers).\n",
    "\n",
    "    weights : array-like, shape = [n_classifiers], optional (default=None)\n",
    "      If a list of `int` or `float` values are provided, the classifiers\n",
    "      are weighted by importance; Uses uniform weights if `weights=None`.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value\n",
    "                                  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit classifiers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
    "            Matrix of training examples.\n",
    "\n",
    "        y : array-like, shape = [n_examples]\n",
    "            Vector of target class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
    "                             \"; got (vote=%r)\"\n",
    "                             % self.vote)\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d classifiers'\n",
    "                             % (len(self.weights), len(self.classifiers)))\n",
    "\n",
    "        # Use LabelEncoder to ensure class labels start with 0, which\n",
    "        # is important for np.argmax call in self.predict\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
    "            Matrix of training examples.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        maj_vote : array-like, shape = [n_examples]\n",
    "            Predicted class labels.\n",
    "            \n",
    "        \"\"\"\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:  # 'classlabel' vote\n",
    "\n",
    "            #  Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in self.classifiers_]).T\n",
    "\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                                      lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions)\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict class probabilities for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
    "            Training vectors, where n_examples is the number of examples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        avg_proba : array-like, shape = [n_examples, n_classes]\n",
    "            Weighted average probability for each class per example.\n",
    "\n",
    "        \"\"\"\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in self.named_classifiers.items():\n",
    "                for key, value in step.get_params(deep=True).items():\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493d8e8-f2c2-4ef2-b861-adc9ef22d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[50:, [1, 2]], iris.target[50:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "       train_test_split(X, y, \n",
    "                        test_size=0.5, \n",
    "                        random_state=1,\n",
    "                        stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372da81-7854-4fc9-8aa0-6523a1392f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf1 = LogisticRegression(penalty='l2', \n",
    "                          C=0.001,\n",
    "                          solver='lbfgs',\n",
    "                          random_state=1)\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=1,\n",
    "                              criterion='entropy',\n",
    "                              random_state=0)\n",
    "\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,\n",
    "                            p=2,\n",
    "                            metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([['sc', StandardScaler()],\n",
    "                  ['clf', clf1]])\n",
    "pipe3 = Pipeline([['sc', StandardScaler()],\n",
    "                  ['clf', clf3]])\n",
    "\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac63461-3abb-4146-9593-d840ca727333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Rule (hard) Voting\n",
    "\n",
    "mv_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])\n",
    "\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [pipe1, clf2, pipe3, mv_clf]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf95a02-8a03-4d5d-9f03-5b68ddcc1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "colors = ['black', 'orange', 'blue', 'green']\n",
    "linestyles = [':', '--', '-.', '-']\n",
    "for clf, label, clr, ls \\\n",
    "        in zip(all_clf,\n",
    "               clf_labels, colors, linestyles):\n",
    "\n",
    "    # assuming the label of the positive class is 1\n",
    "    y_pred = clf.fit(X_train,\n",
    "                     y_train).predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,\n",
    "                                     y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)\n",
    "    plt.plot(fpr, tpr,\n",
    "             color=clr,\n",
    "             linestyle=ls,\n",
    "             label='%s (auc = %0.2f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         linestyle='--',\n",
    "         color='gray',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)')\n",
    "plt.ylabel('True positive rate (TPR)')\n",
    "\n",
    "\n",
    "#plt.savefig('images/07_04', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b207cf-a8f5-4c39-a5ac-9b546c32ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95937ae5-7548-424b-a495-0c3493d5a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "all_clf = [pipe1, clf2, pipe3, mv_clf]\n",
    "\n",
    "x_min = X_train_std[:, 0].min() - 1\n",
    "x_max = X_train_std[:, 0].max() + 1\n",
    "y_min = X_train_std[:, 1].min() - 1\n",
    "y_max = X_train_std[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(nrows=2, ncols=2, \n",
    "                        sharex='col', \n",
    "                        sharey='row', \n",
    "                        figsize=(7, 5))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1]),\n",
    "                        all_clf, clf_labels):\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.3)\n",
    "    \n",
    "    axarr[idx[0], idx[1]].scatter(X_train_std[y_train==0, 0], \n",
    "                                  X_train_std[y_train==0, 1], \n",
    "                                  c='blue', \n",
    "                                  marker='^',\n",
    "                                  s=50)\n",
    "    \n",
    "    axarr[idx[0], idx[1]].scatter(X_train_std[y_train==1, 0], \n",
    "                                  X_train_std[y_train==1, 1], \n",
    "                                  c='green', \n",
    "                                  marker='o',\n",
    "                                  s=50)\n",
    "    \n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "\n",
    "plt.text(-3.5, -5., \n",
    "         s='Sepal width [standardized]', \n",
    "         ha='center', va='center', fontsize=12)\n",
    "plt.text(-12.5, 4.5, \n",
    "         s='Petal length [standardized]', \n",
    "         ha='center', va='center', \n",
    "         fontsize=12, rotation=90)\n",
    "\n",
    "#plt.savefig('images/07_05', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13fd19-2589-4f8f-9fa4-54df66ad1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de745a8-1832-4136-b550-64d7e5c4d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {'decisiontreeclassifier__max_depth': [1, 2],\n",
    "          'pipeline-1__clf__C': [0.001, 0.1, 100.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=mv_clf,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    #iid=False,\n",
    "                    scoring='roc_auc')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_['mean_test_score'][r], \n",
    "             grid.cv_results_['std_test_score'][r] / 2.0, \n",
    "             grid.cv_results_['params'][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285efd2-9c1c-4762-bc94-7d0e3a6b355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606de3ac-dcf5-4fbe-bd8d-58b8a7cb0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01e316-0e92-4eca-9176-93a8a5f491bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c697cf4-49a5-4ada-90e7-1c16b6e151b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf.set_params(**grid.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fc417-bb06-409b-8f9e-c3426a6fbf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849dacc-e7c6-4398-bced-978b02f7f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                      'machine-learning-databases/wine/wine.data',\n",
    "                      header=None)\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                   'Proline']\n",
    "\n",
    "# if the Wine dataset is temporarily unavailable from the\n",
    "# UCI machine learning repository, un-comment the following line\n",
    "# of code to load the dataset from a local path:\n",
    "\n",
    "# df_wine = pd.read_csv('wine.data', header=None)\n",
    "\n",
    "# drop 1 class\n",
    "df_wine = df_wine[df_wine['Class label'] != 1]\n",
    "\n",
    "y = df_wine['Class label'].values\n",
    "X = df_wine[['Alcohol', 'OD280/OD315 of diluted wines']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76533454-889d-46bf-a456-fe76fcf6ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "            train_test_split(X, y, \n",
    "                             test_size=0.2, \n",
    "                             random_state=1,\n",
    "                             stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802203b-39cc-4277-91e9-6a24a68096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=None,\n",
    "                              random_state=1)\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=tree,\n",
    "                        n_estimators=500, \n",
    "                        max_samples=1.0, \n",
    "                        max_features=1.0, \n",
    "                        bootstrap=True, \n",
    "                        bootstrap_features=False, \n",
    "                        n_jobs=1, \n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b024aee-7165-46a2-9844-617607f0e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree = tree.fit(X_train, y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f'\n",
    "      % (tree_train, tree_test))\n",
    "\n",
    "bag = bag.fit(X_train, y_train)\n",
    "y_train_pred = bag.predict(X_train)\n",
    "y_test_pred = bag.predict(X_test)\n",
    "\n",
    "bag_train = accuracy_score(y_train, y_train_pred) \n",
    "bag_test = accuracy_score(y_test, y_test_pred) \n",
    "print('Bagging train/test accuracies %.3f/%.3f'\n",
    "      % (bag_train, bag_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588cdd8-ea13-4aaa-9e98-42291854390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_min = X_train[:, 0].min() - 1\n",
    "x_max = X_train[:, 0].max() + 1\n",
    "y_min = X_train[:, 1].min() - 1\n",
    "y_max = X_train[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(nrows=1, ncols=2, \n",
    "                        sharex='col', \n",
    "                        sharey='row', \n",
    "                        figsize=(8, 3))\n",
    "\n",
    "\n",
    "for idx, clf, tt in zip([0, 1],\n",
    "                        [tree, bag],\n",
    "                        ['Decision tree', 'Bagging']):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axarr[idx].scatter(X_train[y_train == 0, 0],\n",
    "                       X_train[y_train == 0, 1],\n",
    "                       c='blue', marker='^')\n",
    "\n",
    "    axarr[idx].scatter(X_train[y_train == 1, 0],\n",
    "                       X_train[y_train == 1, 1],\n",
    "                       c='green', marker='o')\n",
    "\n",
    "    axarr[idx].set_title(tt)\n",
    "\n",
    "axarr[0].set_ylabel('OD280/OD315 of diluted wines', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.text(0, -0.2,\n",
    "         s='Alcohol',\n",
    "         ha='center',\n",
    "         va='center',\n",
    "         fontsize=12,\n",
    "         transform=axarr[1].transAxes)\n",
    "\n",
    "#plt.savefig('images/07_08.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d2dc2-83ae-4ff2-96a6-4305fe129017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=1,\n",
    "                              random_state=1)\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=tree,\n",
    "                         n_estimators=500, \n",
    "                         learning_rate=0.1,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c98e9-773e-4eea-9c0e-a72e1eb44d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree.fit(X_train, y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f'\n",
    "      % (tree_train, tree_test))\n",
    "\n",
    "ada = ada.fit(X_train, y_train)\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "\n",
    "ada_train = accuracy_score(y_train, y_train_pred) \n",
    "ada_test = accuracy_score(y_test, y_test_pred) \n",
    "print('AdaBoost train/test accuracies %.3f/%.3f'\n",
    "      % (ada_train, ada_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6068a-fe0f-4ac3-998f-78ce66c07f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(8, 3))\n",
    "\n",
    "\n",
    "for idx, clf, tt in zip([0, 1],\n",
    "                        [tree, ada],\n",
    "                        ['Decision tree', 'AdaBoost']):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axarr[idx].scatter(X_train[y_train == 0, 0],\n",
    "                       X_train[y_train == 0, 1],\n",
    "                       c='blue', marker='^')\n",
    "    axarr[idx].scatter(X_train[y_train == 1, 0],\n",
    "                       X_train[y_train == 1, 1],\n",
    "                       c='green', marker='o')\n",
    "    axarr[idx].set_title(tt)\n",
    "\n",
    "axarr[0].set_ylabel('OD280/OD315 of diluted wines', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.text(0, -0.2,\n",
    "         s='Alcohol',\n",
    "         ha='center',\n",
    "         va='center',\n",
    "         fontsize=12,\n",
    "         transform=axarr[1].transAxes)\n",
    "\n",
    "#plt.savefig('images/07_11.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
